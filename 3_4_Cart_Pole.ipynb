{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmeycFtINfPR0QOU9Y/4gx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luke-687/Portfolio/blob/main/3_4_Cart_Pole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "#Establish environment\n",
        "env = gym.make('CartPole-v1', render_mode = None)\n",
        "\n",
        "#Establish bounds of environment\n",
        "def boundaries():\n",
        "  bounds = [\n",
        "      np.linspace(-4.8,4.8,10), #Cart Pos.\n",
        "      np.linspace(-4,4,10), #cart vel.\n",
        "      np.linspace(-0.9, 0.9, 10), #Pole ang.\n",
        "      np.linspace(-4,4,10) #Pole vel. at tip\n",
        "  ]\n",
        "  return bounds\n",
        "\n",
        "def discretize(obs, bins):\n",
        "    return tuple(int(np.digitize(x, b) - 1) for x, b in zip(obs, bins))\n",
        "\n",
        "#Begin to set up MDP\n",
        "actions = env.action_space.n\n",
        "bins = boundaries()\n",
        "gamma = 0.4\n",
        "theta = 0.0001\n",
        "\n",
        "V = defaultdict(float)\n",
        "policy = {}\n",
        "\n",
        "def optimize(iterations):\n",
        "  for x in range(0, iterations):\n",
        "    d = 0\n",
        "    for i in range(0,10):\n",
        "      for j in range(0,10):\n",
        "        for k in range(0,10):\n",
        "          for l in range(0,10):\n",
        "            #d tracks convergence\n",
        "            state = (i,j,k,l)\n",
        "            v = V[state]\n",
        "            max_value = float('-inf')\n",
        "            bestAct = 0\n",
        "            for a in range(actions):\n",
        "              total = 0\n",
        "              for z in range(0,5):\n",
        "                obs = [\n",
        "                      (bins[0][i] + bins[0][min(i+1, 9)]) / 2,\n",
        "                      (bins[1][j] + bins[1][min(j+1, 9)]) / 2,\n",
        "                      (bins[2][k] + bins[2][min(k+1, 9)]) / 2,\n",
        "                      (bins[3][l] + bins[3][min(l+1, 9)]) / 2\n",
        "                      ]\n",
        "                env.reset()\n",
        "                env.unwrapped.state = np.array(obs)\n",
        "                obs, reward, terminated, truncated, _ = env.step(a)\n",
        "                done = terminated or truncated\n",
        "                disc_obs = discretize(obs, bins)\n",
        "                total += reward + gamma * V[disc_obs] * (0 if done else 1)\n",
        "              total/=5\n",
        "              if total>max_value:\n",
        "                max_value = total\n",
        "                bestAct = a\n",
        "            V[state] = max_value\n",
        "            policy[state] = bestAct\n",
        "            d = max(d, abs(v-max_value))\n",
        "            iterations+=1\n",
        "        if theta>d:\n",
        "          break\n",
        "  return V, policy\n",
        "\n",
        "#Run model (use the policy)\n",
        "def run(render=False):\n",
        "    obs, x = env.reset()\n",
        "    totReward = 0\n",
        "\n",
        "    for t in range(500):  #500 posible trials\n",
        "        state = discretize(obs, bins)\n",
        "        action = policy.get(state, env.action_space.sample())  # fallback to random if unseen\n",
        "        obs, reward, terminated, truncated, x = env.step(action)\n",
        "        totReward += reward\n",
        "        if render:\n",
        "            env.render()\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return totReward"
      ],
      "metadata": {
        "id": "bdi7bMZzybtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create policy\n",
        "V,policy = optimize(1)\n",
        "\n",
        "#Find rewards\n",
        "timesTested = 10000  #Num times tested\n",
        "scores = [run(render=False) for x in range(timesTested)]\n",
        "print(f\"Average Reward over 100 episodes: {np.mean(scores)}\")\n",
        "print(f\"Max Reward: {np.max(scores)}\")\n",
        "print(f\"Min Reward: {np.min(scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHGg3qktgwqb",
        "outputId": "ad1312db-d86e-4e1d-d26f-c9fb21cdd60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Reward over 100 episodes: 9.3612\n",
            "Max Reward: 11.0\n",
            "Min Reward: 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sim is from chat gpt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def draw_cartpole(cart_position, pole_angle):\n",
        "    fig, ax = plt.subplots(figsize=(6, 3))\n",
        "    ax.set_xlim(-2.5, 2.5)\n",
        "    ax.set_ylim(-1, 1.5)\n",
        "\n",
        "    # Draw cart\n",
        "    cart_width = 0.4\n",
        "    cart_height = 0.2\n",
        "    cart = plt.Rectangle((cart_position - cart_width / 2, 0), cart_width, cart_height, fc='black')\n",
        "    ax.add_patch(cart)\n",
        "\n",
        "    # Draw pole\n",
        "    pole_length = 1.0\n",
        "    pole_x = cart_position + pole_length * np.sin(pole_angle)\n",
        "    pole_y = cart_height + pole_length * np.cos(pole_angle)\n",
        "    ax.plot([cart_position, pole_x], [cart_height, pole_y], lw=3, color='blue')\n",
        "\n",
        "    # Draw ground\n",
        "    ax.axhline(0, color='gray', lw=2)\n",
        "\n",
        "    ax.set_title(\"CartPole Simulation\")\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def run_visual_episode(env, policy, bins, delay=0.05):\n",
        "    obs, x = env.reset()\n",
        "    total_reward = 0\n",
        "    for x in range(500):\n",
        "        clear_output(wait=True)\n",
        "        cart_pos = obs[0]\n",
        "        pole_ang = obs[2]\n",
        "        draw_cartpole(cart_pos, pole_ang)\n",
        "\n",
        "        state = discretize(obs, bins)\n",
        "        action = policy.get(state, env.action_space.sample())\n",
        "        obs, reward, terminated, truncated, x = env.step(action)\n",
        "        total_reward += reward\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "        time.sleep(delay)\n",
        "    print(f\"Total reward: {total_reward}\")\n",
        "\n",
        "run_visual_episode(env, policy, bins, delay=0.1)"
      ],
      "metadata": {
        "id": "UbvPClhnhTwy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "41376ea7-a51c-41a3-f7c9-672e669f2256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reward: 9.0\n"
          ]
        }
      ]
    }
  ]
}